quarkus.langchain4j.huggingface.api-key=${HUGGING_FACE_API_KEY}
quarkus.langchain4j.huggingface.chat-model.inference-endpoint-url=https://api-inference.huggingface.co/models/ibm-granite/granite-3.0-8b-instruct
quarkus.langchain4j.huggingface.chat-model.temperature = 0

quarkus.langchain4j.huggingface.log-requests=true
quarkus.langchain4j.huggingface.log-responses=true

#quarkus.langchain4j.chat-memory.memory-window.max-messages = 1

#quarkus.langchain4j.ollama.base-url = http://localhost:11434
#quarkus.langchain4j.ollama.timeout = 1m
#quarkus.langchain4j.ollama.chat-model.model-id = granite3-dense
#quarkus.langchain4j.ollama.chat-model.format = json
#quarkus.langchain4j.ollama.chat-model.temperature = 0

quarkus.native.resources.includes=texts/*.txt